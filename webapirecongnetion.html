<!DOCTYPE html>
<html lang="fr">

<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Chrome Speech Recognition avec indicateur visuel</title>
    <style>
        /* Styles pour le bouton d'écoute */
        #start {
            padding: 10px 20px;
            font-size: 16px;
            cursor: pointer;
            background-color: #007BFF;
            color: white;
            border: none;
            border-radius: 5px;
        }

        /* Lorsque la reconnaissance vocale est active */
        #start.listening {
            background-color: #28a745;
            /* Couleur verte quand l'écoute est active */
        }
    </style>
</head>

<body>
    <h1>Transcription continue avec détection du mot "David"</h1>
    <button id="start">Commencer la reconnaissance vocale</button>
    <p>Transcription : <span id="transcript"></span></p>
    <p>Valeur de la variable : <span id="variable">1</span></p>
    <p>Transcriptions collectées : <span id="collected-transcripts"></span></p>

    <!-- Ajout du CDN d'Axios -->
    <script src="https://cdn.jsdelivr.net/npm/axios/dist/axios.min.js"></script>

    <script>
        const startButton = document.getElementById('start');
        const transcriptOutput = document.getElementById('transcript');
        const variableOutput = document.getElementById('variable');
        const collectedTranscriptsOutput = document.getElementById('collected-transcripts');

        let variable = 1; // Variable initialisée à 1
        let collectedTranscripts = []; // Variable pour stocker les transcripts sous forme de tableau

        // Vérification de la disponibilité de l'API Web Speech
        if (!('webkitSpeechRecognition' in window)) {
            alert('Votre navigateur ne supporte pas la reconnaissance vocale.');
        } else {
            const recognition = new webkitSpeechRecognition();
            recognition.continuous = true; // Reconnaissance continue
            recognition.interimResults = false; // Résultats finaux uniquement
            recognition.lang = 'fr-FR'; // Langue de reconnaissance

            recognition.onresult = function (event) {
                let transcript = '';
                for (let i = event.resultIndex; i < event.results.length; ++i) {
                    transcript += event.results[i][0].transcript;
                }
                transcriptOutput.textContent = transcript;

                // Vérifier si "David" est dans la transcription
                if (transcript.toLowerCase().includes("dieu")) {
                    variable = 2; // Changer la valeur de la variable à 2
                    variableOutput.textContent = variable; // Mettre à jour l'affichage

                    // Supprimer le dernier transcript ajouté
                    if (collectedTranscripts.length < 1) {
                        collectedTranscripts.pop(transcript); // Retirer le dernier élément du tableau
                        collectedTranscriptsOutput.textContent = collectedTranscripts.join(' '); // Mettre à jour l'affichage
                    }
                }

                // Si la variable est 2, ajouter le transcript à collectedTranscripts
                if (variable === 2 && !transcript.toLowerCase().includes("dieu")) {
                    collectedTranscripts.push(transcript); // Ajouter le transcript au tableau
                    collectedTranscriptsOutput.textContent = collectedTranscripts.join(' '); // Mettre à jour l'affichage
                }

                // Si "merci" est détecté, arrêter la reconnaissance vocale et envoyer une requête POST
                if (variable === 2 && transcript.toLowerCase().includes("merci")) {
                    collectedTranscripts.pop("merci");
                    console.log(collectedTranscriptsOutput.textContent);

                    // Arrêter la reconnaissance vocale
                    recognition.stop();
                    startButton.classList.remove('listening'); // Retirer l'indicateur visuel

                    // Envoyer la requête POST avec Axios
                    axios.post('https://api.groq.com/openai/v1/chat/completions', {
                        messages: [
                            {
                                role: "user",
                                content: collectedTranscriptsOutput.textContent
                            }
                        ],
                        model: "llama3-8b-8192"
                    }, {
                        headers: {
                            'Authorization': 'Bearer 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',
                            'Content-Type': 'application/json'
                        }
                    })
                    .then(response => {
                        console.log('Réponse de l\'API :', response.data);
                    })
                    .catch(error => {
                        console.error('Erreur lors de l\'appel API:', error);
                    });
                }
            };

            recognition.onerror = function (event) {
                console.error('Erreur de reconnaissance vocale:', event.error);
            };

            // Démarrer la reconnaissance vocale lors du clic sur le bouton
            startButton.addEventListener('click', () => {
                recognition.start();
                startButton.classList.add('listening'); // Ajouter une classe quand l'écoute commence
            });

            recognition.onend = function () {
                startButton.classList.remove('listening'); // Retirer la classe quand l'écoute s'arrête
            };
        }
    </script>
</body>

</html>
